# Slow Web Server

Bir kullanıcı, şirketimizdeki web sunucularından birinin yavaşladığını bildirdi ve neyin olduğunu anlamamız gerekiyor. İlk olarak, web sitesine gidip sayfayı yükleyerek başlayalım. Tamam, sayfanın yüklendiğini görüyoruz. Biraz yavaş gibi görünüyor ama bunu kendi başımıza ölçmek zor. Bu yüzden Apache Benchmark aracı olan **"ab"** aracını kullanarak ne kadar yavaş olduğunu belirlemek için bir araç kullanalım. Ortalama 500 isteğin süresini almak için **"ab -n 500"** komutunu çalıştıracağız ve ölçüm için "site.example.com" adresini ileteceğiz. Bu araç, bir web sitesinin beklenildiği gibi davranıp davranmadığını kontrol etmek için son derece faydalıdır. Bir dizi istek yapacak ve işlem tamamlandığında sonuçları özetleyecektir. Burada, web sitemize 500 istek yapmasını istiyoruz. Aynı anda programın kaç istek yapmasını istediğimiz gibi geçersiz kılma veya testin süresi dolmuş olsa bile tamamlanmasını isteme gibi çok daha fazla seçenek var, 500 istek yaparak işlerin ne kadar sürede olduğunun ortalama değerini alabiliriz. Test tamamlandığında, verilere bakabilir ve gerçekten yavaş olup olmadığına karar verebiliriz. Tamam, araç 500 isteği çalıştırmayı bitirdi. Ortalama istek başına zamanın 155 milisaniye olduğunu görüyoruz. Bu çok büyük bir sayı olmasa da, böyle basit bir web sitesi için beklediğimizden kesinlikle daha fazla. Web sunucusunda bir sorun olduğu görünüyor ve daha fazla inceleme yapmamız gerekiyor. Web sunucusuna bağlanıp ne olduğuna bakalım. İlk olarak, **top** çıktısına bakarak ve orada şüpheli bir şey olup olmadığını görelim. Bir sürü ffmpeg işlemi çalıştığını görüyoruz ve temelde mevcut tüm CPU'yu kullanıyorlar. Yük sayılarını gördünüz mü? Otuz kesinlikle normal değil. Linux'taki yük ortalaması, işlemcinin bir dakika boyunca ne kadar sürekli meşgul olduğunu gösterir ve bir, işlemcinin bir dakika boyunca sürekli meşgul olduğu anlamına gelir. Bu bilgisayarın iki işlemcisi var. Dolayısıyla, iki'nin üzerindeki herhangi bir sayı, aşırı yüklü olduğunu gösterir. Her dakika, işlemci zamanı bekleyen süreçler, işlemcinin verebileceğinden daha fazladır. Bu ffmpeg programı, dosyaları bir video formatından diğerine dönüştürme işlemi olan video transkodlaması için kullanılır. Bu, CPU yoğun bir işlemdir ve sunucumuzun aşırı yüklenmesinin muhtemel nedeni gibi görünüyor. Peki ne yapabiliriz? Deneyebileceğimiz bir şey, işlem önceliklerini değiştirmektir, böylece web sunucusu öncelik kazanır. Linux'taki işlem öncelikleri, sayı ne kadar düşükse öncelik o kadar yüksektir. Tipik sayılar 0 ila 19 arasında değişir. Varsayılan olarak, işlemler sıfır öncelikle başlar. Ancak bunu **nice ve renice** komutlarını kullanarak değiştirebiliriz. Bir işlemi farklı bir öncelikle başlatmak için "nice"i ve zaten çalışan bir işlemin önceliğini değiştirmek için "renice"i kullanırız. Tamam, top çıktısından çıkış yapalım ve öncelikleri değiştirelim. Şu anda çalışan tüm ffmpeg işlemleri için "renice" komutunu çalıştırmak istiyoruz. Bunu birer birer yapabilirdik. Ancak bu manuel, hata yapmaya meyilli ve son derece sıkıcı olurdu. Bunun yerine, bunu bizim için yapacak kısa bir kabuk betiği satırı kullanabiliriz. Bunun için, işlem adını alan ve bu adı alan tüm işlem kimliklerini döndüren **"pidof"** komutunu kullanacağız. "pidof" komutunun çıktısı üzerinde bir "for" döngüsü ile yineleme yapacağız ve ardından her bir işlem kimliği için "renice" komutunu çağıracağız. "renice", yeni önceliği ilk argüman olarak ve değiştirilecek işlem kimliğini ikinci argüman olarak alır. Bizim durumumuzda, en düşük mümkün önceliği isteyeceğiz, yani 19. Bu yüzden $(pidof ffmpeg) için pid in içinde döngü yapacağız; yap renice 19 $pid; bitti. Tamam, bu işlemlerin öncelikleri güncellendi. Şimdi bir kez daha benchmark yazılımımızı çalıştıralım ve herhangi bir fark olup olmadığını kontrol edelim. Tamam, tekrar çalışıyor. 500 istek tamamlanana kadar beklememiz gerekecek ve yeni ortalama istek süresini kontrol etmemiz gerekecek. Bu sefer, ortalama süre 153 milisaniye. Renice'ın yardımcı olmadığı görünüyor. Görünüşe göre işletim sistemi, hala bu ffmpeg işlemlerine çok fazla işlemci zamanı veriyor. Web sitemiz hala yavaş. Ne yapabiliriz? Bu transkodlama işlemleri, CPU yoğun olduğu için ve bunları paralel olarak çalıştırmak bilgisayarı aşırı yüklüyor olduğundan, yapabileceğimiz bir şey, bunları aynı anda çalıştırmak yerine birbiri ardına çalıştırmayı tetikleyen her neyse onu değiştirmektir. Bunun için, bu işlemlerin nasıl başlatıldığını bulmamız gerekecek. İlk olarak, işlemler hakkında daha fazla bilgi almak için **"ps"** komutunun çıktısına bakacağız. Bize bilgisayarın tüm çalışan işlemlerini gösteren **"ps ax"** komutunu çalıştıracağız ve çıktıyı inceleyebilmek için komutun çıktısını **"less"**e bağlayacağız. Şimdi "less" kullanırken arama tuşu olan **"slash"** kullanarak ffmpeg işlemini bulacağız. Tamam, bir sürü ffmpeg işleminin webm formatındaki videoları mp4 formatına dönüştürdüğünü görüyoruz. Bu videoların sabit sürücüde nerede olduğunu bilmiyoruz. Onları bulmak için **"locate"** komutunu kullanmayı deneyebiliriz. Önce "less" arayüzünden çıkış yapalım ve sonra locate static/001.webm komutunu çalıştıralım. "Static" dizininin sunucuda dağıtılan videolar dizininde olduğunu görüyoruz. O dizine geçelim ve ne bulacağımıza bakalım. Burada bir sürü dosya var. Birer birer kontrol edebiliriz ve bunların ffmpeg çağrısı içerip içermediğini görebiliriz. Ancak bu çok fazla manuel iş gibi görünüyor. Bunun yerine, bu dosyalardan herhangi birinin bir ffmpeg çağrısı içerip içermediğini kontrol etmek için "grep"i kullanalım. Bu dosyada birkaç ffmpeg bahsi olduğunu görüyoruz. Buna bir göz atalım. Uzaktan sunucuya bağlandığımız için, dosyayı grafiksel bir düzenleyici kullanarak açamıyoruz. Bunun yerine komut satırı düzenleyicisi kullanmamız gerekecek. Bu durumda "vim" kullanacağız. Bu komut dosyasının, Daemonize adlı bir araç kullanarak ffmpeg işlemlerini paralel olarak başlattığını görüyoruz, her bir programı birbirinden bağımsız olarak bir daemon gibi çalıştırır. Bu, sadece birkaç videoyu dönüştürmemiz gerekiyorsa kabul edilebilir olabilir, ancak statik dizinindeki her bir video için ayrı bir işlem başlatmak sunucumuzu aşırı yüklüyor. Bu nedenle, bu işlemi yalnızca bir video dönüştürme işlemi çalıştıracak şekilde değiştirmek istiyoruz. Bunu, sadece daemonize edilmiş kısmı silerek ve ffmpeg'i çağırma kısmını saklayarak yapacağız, sonra kaydedip çıkacağız. Tamam, dosyayı değiştirdik. Ancak bu, zaten çalışan işlemleri değiştirmeyecek. Bu işlemleri durdurmak istiyoruz ama bunları tamamen iptal etmek istemiyoruz, çünkü bu, şu anda dönüştürülmekte olan videoların eksik olacağı anlamına gelir. Bu nedenle, işlemleri durdurmak için ancak tamamen öldürmemek için "killall" komutunu "-STOP" bayrağı ile kullanacağız. Şimdi bu işlemleri birer birer çalıştırmak istiyoruz. Bunun için nasıl yapabiliriz? Birine **CONT** sinyali gönderebiliriz, bitene kadar bekleriz ve sonra bir sonrakine göndeririz. Ancak bu çok fazla manuel iş. Otomatikleştirebilir miyiz? Evet. Ama biraz karmaşık. Bu yüzden dikkatlice dinleyin. Daha önce kullandığımız pit of komutuyla aynı for döngüsünü kullanarak işlemlerin listesini dolaşabiliriz. For döngüsünün içinde, cont sinyali göndermek ve işlem bitene kadar beklemek istiyoruz. Ne yazık ki, işlem bitene kadar bekleyecek bir komut yok. Ancak işlem yok olduğunda başarılı olacak ve işlem gittikten sonra başarısız olacak bir while döngüsü oluşturabiliriz. Bu while döngüsünün içine, bir sonraki kontrol için bir saniye beklemek için bir "sleep one" komutu ekleyeceğiz. Tamam, şimdi sunucumuz bir ffmpeg işlemi çalıştırıyor. Bir kez daha benchmark'ı çalıştıralım. Ortalama süre şimdi 33 milisaniye. Bu öncekinden çok daha düşük. Web sunucumuzun isteklere hızlı yanıt vermesini sağladık. Kodu düzeltemediğimizde alabileceğimiz birkaç farklı yaklaşımı belirttik, işlemlerin önceliklerini değiştirmek gibi veya bunlar işe yaramadığında işlemleri birbirini izleyecek şekilde çalıştırmak gibi. Bir sonraki videolarımızda, kodumuzu düzelterek performansı nasıl artırabileceğimizi tartışacağız. Ancak bundan önce, bahsettiğimiz tüm kaynakları bir araya getirecek bir okuma ve her şeyin anlaşılır olup olmadığını kontrol etmek için hızlı bir sınav var.

A user has alerted us that one of the web servers in our company is being slow, and we need to figure out what's going on. Let's start by navigating to the website and loading the page. Okay. We see that the page loads. It seems to be a little slow but it's hard to measure this on our own. Let's use a tool called ab which stands for Apache Benchmark tool to figure out how slow it is. We'll run ab -n 500 to get the average timing of 500 requests, and then pass our site.example.com for the measurement. This tool is super useful for checking if a website is behaving as expected or not. It will make a bunch of requests and summarize the results once it's done. Here, were asking for it to do 500 requests to our website. There are a lot more options that we could pass like how many requests we want the program to do at the same time, or if the test to finish after timeout, even if not all requests completed, we're making 500 requests so that we can get an average of how long things are taking. Once the test finishes, we can look at the data and decide if it's actually slow or not. All right. The tool has finished running the 500 requests. We see that the mean time per requests was a 155 milliseconds. While this is not a super huge number, it's definitely more than what we'd expect for such a simple website. It seems that something is going on with the web server and we need to investigate further. Let's connect to the web server and check out what's going on. We'll start by looking at the output of top and see if there's anything suspicious there. We see that there's a bunch of ffmpeg processes running, which are basically using all the available CPU. See those load numbers? Thirty is definitely not normal. Remember that the load average on Linux shows how much time the processor is busy at a given minute with one meaning it was busy for the whole minute. This computer has two processors. So any number above two means that it's overloaded. During each minute, there were more processes waiting for processor time than the processor had to give. This ffmpeg program is used for video transcoding which means converting files from one video format to another. This is a CPU intensive process and seems like the likely culprit for our server being overloaded. So what can we do? One thing we can try is to change the processes priorities so that the web server takes precedence. The process priorities in Linux are so that the lower the number, the higher the priority. Typical numbers go from 0 to 19. By default, processes start with a priority of zero. But we can change that using the nice and renice commands. We use nice for starting a process with a different priority and renice for changing the priority of a process that's already running. Okay. Let's exit top with queue and change the priorities. We want to run renice for all the ffmpeg processes that are running right now. We could do this one by one. But it would be manual, error-prone, and super boring. Instead, we can use a quick line of shell script to do this for us. For that, we'll use the pidof command that receives the process name and returns all the process IDs that have that name. We'll iterate over the output of the pidof command with a for loop and then call renice for each of the process IDs. Renice takes the new priority as the first argument, and the process ID to change as the second one. In our case, we'll want the lowest possible priority which is 19. So we'll call for pid in $(pidof ffmpeg); do renice 19 $pid; done. All right. We see that the priorities for those processes were updated. Let's run our benchmarking software again and check out if it made any difference. Okay. It's running once again. We'll need to wait until the 500 requests are done and check out the new meantime per request value. This time, the meantime is 153 milliseconds. It doesn't seem like our renice helped. Apparently, the OS is still giving these ffmpeg processes way too much processor time. Our website is still slow. What else can we do? These transcoding processes are CPU intensive, and running them in parallel is overloading the computer. So one thing we could do is, modify whatever's triggering them to run them one after the other instead of all at the same time. To do that, we'll need to find out how these processes got started. First, we'll look at the output of the ps command to get some more information about the processes. We'll call ps ax which shows us all the running processes on the computer, and we'll connect the output of the command to less, to be able to scroll through it. Now we'll look for the ffmpeg process using slash which is the search key when using less. Okay. We see that there are a bunch of ffmpeg processes that are converting videos from the webm format to the mp4 format. We don't know where these videos are on the hard drive. We can try using the locate command to see if we can find them. We'll first exit the less interface with queue and then call locate static/001.webm. We see that the static directory is located in the server deploy videos directory. Let's change into that directory and see what we find. There's a bunch of files here. We could check them all one-by-one to see if one of them contained a call to ffmpeg. But that sounds like a lot of manual work. Instead, let's use grep to check if any of these files contains a call to ffmpeg. So we see that there's a couple of mentions in the deployed sh file. Let's take a look at that one. Since we're connecting to the server remotely, we can't open the file using a graphical editor. We need to use a command line editor instead. We'll use vim in this case. We see that this script is starting the ffmpeg processes in parallel using a tool called Daemonize that runs each program separately as if it were a daemon. This might be okay if we only need to convert a couple of videos but launching one separate process for each of the videos in the static directory is overloading our server. So we want to change this to run only one video conversion process at a time. We'll do that by simply deleting the daemonized part and keeping the part that calls ffmpeg, then save and exit. All right. We've modified the file. But this won't change the processes that are already running. We want to stop these processes but not cancel them completely, as doing so would mean that the videos being converted right now will be incomplete. So we'll use the killall command with the -STOP flag which sends a stop signal but doesn't kill the processes completely. We now want to run these processes one at a time. How can we do that? We could send the CONT signal to one of them, wait till it's done, and then send it to the next one. But that's a lot of manual work. Can be automate it? Yes. But it's a little tricky. So pay close attention. We can iterate through the list of processes using the same for loop with the pit of command that we used earlier. Inside the for loop, we want to send the cont signal and then wait until the process is done. Unfortunately, there's no command to wait until the process finishes. But we can create a while loop that sends the cont signal to the process. This will succeed as long as the process exists, and fails once the process goes away. Inside this while loop, we'll simply add a call to sleep one, to wait one second until the next check. Okay. Now our server is running one ffmpeg process at a time. Let's turn our benchmark once more. The mean time is now 33 milliseconds. That's much lower than before. We've managed to get our web server to reply promptly to the request again. We've mentioned a few different approaches that we can take when we can't fix the code like renicing the processes, or running them one after the other when that doesn't help. In our next few videos, we'll talk about how to improve performance by fixing our code. But before that, there's a reading to put all the resources we mentioned in one place, and then a quick quiz to check if everything is making sense.