# Dealing with Memory Leaks

Bir uygulamanın çok miktarda bellek istemesinin bir ton nedeni olabilir. Bazen, programın görevini tamamlaması için ihtiyacımız olan budur. Bazen, yazılımın bir bölümünün kötü davranışından kaynaklanır. İlk olarak, bu kötü davranışı kendimiz tetikleyelim ve bunun nasıl göründüğünü görelim. Bunu yapmak için **uxterm** adlı bir terminal kullanacağız. Bu terminali gerçekten uzun bir kaydırma tamponuna sahip olacak şekilde yapılandırdık. Kaydırma tamponu, yaptığımız işlemleri ve çıktılarını görmemize izin veren şık bir özelliktir. Tamponun içeriği bellekte tutulur. Bu nedenle onu gerçekten uzun yaparsak ve onu doldurmayı başarırsak, bilgisayarımızın belleği tükenir. Normal kullanımda bunun olması çok uzun sürebilir, ancak çok miktarda çıktı üreten bir komut çalıştırırsak, tamponu oldukça hızlı bir şekilde doldurmayı başarabiliriz. Mesela **od -cx/dev/urandom** gibi bir komut çalıştıralım. Bu komut, **urandom** cihazı tarafından üretilen rastgele sayıları hem karakterler hem de onaltılı sayılar olarak gösterir. Urandom cihazı sürekli olarak daha fazla rastgele sayı verdiği için, komut devam edecektir. Komutumuz kaydırma tamponunu doldurarak bilgisayarın daha fazla belleğe ihtiyaç duymasına neden oluyor. Başka bir terminalde, **top**'u açalım ve neler olup bittiğini kontrol edelim. **"Shift M"** ye basarak programları ne kadar bellek kullandıklarına göre sıralamak istediğimizi söylüyoruz. Uxterm'in kullandığı belleğin yüzdesinin hızla arttığını görüyoruz. Süreci durduralım, tamponu dolduruyor, **"Control C"** tuşuna basarak. Böylece tamponu dolduran komutu durdurduk, ancak terminal hala belleği ayırdı, tüm satırları kaydırma tamponunda saklıyor. Top'un çıktısına biraz daha detaylı bakalım. Her süreçle ilgili verilere ait bir dizi farklı sütun var. **"RES"** olarak etiketlenmiş sütun, belirli bir süreç için korunan dinamik bellektir. **"SHR"** olarak etiketlenmiş olan, süreçler arasında paylaşılan bellektir ve **"VIRT"** olarak etiketlenmiş olan, her süreç için ayrılan sanal belleği listeler. Bu, süreç özel belleği, paylaşılan bellek ve diskte depolanan ancak sürecin belleğine haritalanan diğer paylaşılan kaynakları içerir. Bir sürecin **VIRT** sütununda yüksek bir değere sahip olması genellikle sorun teşkil etmez. Genellikle sorun teşkil eden, **RES sütunundaki değerdir**. Diğer terminali kapatın, bu şekilde ayrılan tüm belleği serbest bıraksın. Bu örnekte, programın nasıl daha fazla bellek istediğini gördük. Bu aşırı bir örnekti. Çoğu bellek sızıntısı bu hızda gerçekleşmez. Genellikle bir programın beklenenden daha fazla bellek kullanmasını fark etmek uzun sürebilir ve gerçekten ihtiyaç duyulan bellek ile israf edilen bellek arasındaki farkı anlamak zor olabilir. Ancak top'un çıktısına bakmak ve bir süre önce ne olduğuyla karşılaştırmak, genellikle bellek sızıntısıyla ilgili herhangi bir soruşturmanın nasıl başladığıdır. Başka bir örneğe bakalım. Bir betikte web sayfalarındaki kelimelerin frekansını analiz eden bir script'imiz var. Bu betik, sadece birkaç web sayfası olduğunda sorunsuz çalışır, ancak tüm Vikipedi içeriğini verirsek, tüm belleği kullanmaya başlar. Önce çalıştıralım ve ne olacağını görelim. Bu çalışıyor ve bitmesi uzun bir süre alacak. Sonuçta, nihayetinde büyük bir makale miktarını işliyor. Bu çalışırken, farklı bir terminalde top'un çıktısına bakalım ve ne bulduğumuza bakalım. Bir dizi farklı içerik istatistikleri süreci çalıştığını görüyoruz. Bu, betiğimizin bilgi işleminin paralelleştirilmesi ve sonuçları mümkün olan en hızlı şekilde elde etmek için kullandığı çoklu işlemlilik tekniklerini kullandığından kaynaklanmaktadır. Bu betiklerin çok bellek kullandığını görünüyor gibi. Dolayısıyla ayrıntıları görmek için bunu sıralayalım. Bir sürecin kullandığı belleğin sürekli olarak arttığını görüyoruz. Uygulama bir dizi veriyi işliyor ve bununla bir sözlük oluşturuyor. Bu nedenle bir miktar bellek kullanması beklenir, ancak bu kadar çok olmamalıdır. Bu, programın bellekte olması gerektiğinden daha fazlasını sakladığını gösteriyor gibi görünüyor. Bu program oldukça karmaşıktır, bu nedenle burada sorunu anlamak için bir bellek profilleyici kullanabiliriz. Şimdi bunu durdurup bilgisayarımızın belleğinin nereye gittiğini anlamak için bir profilleyici kullanacağız. Bunun için çoklu işlem uygulamasının belleğini profillemek ekstra zordur ve tüm makaleleri işlemek yerine hızlı bir şekilde bellek tüketimini kontrol edebilmemiz için kodumuzun basitleştirilmiş bir versiyonunu kullanacağız. Basitleştirilmiş betiği açalım ve bir göz atalım. **Memory profiler** adlı bir modülü kullanacağız. Bu, Python için birçok farklı bellek profilleyicilerden biridir. Profilleyiciyi kullanmak için ana fonksiyon tanımının önüne bu **app profile** etiketini ekledik. Bu tür bir etiket, bir işlevi değiştirmeden bir Python işlevine ekstra davranış eklemek için kullanılan bir dekoratördür ve bu durumda ek davranış bellek kullanımını ölçmektir. Kodun geri kalanı temelde orijinaliyle aynıdır, tek fark, tek bir işlemi kullanması ve binlerce makale yerine 50 makale ile sınırlı olmasıdır. Bellek profilleyici etkin bir şekilde çalışan bir betik. Bu sadece 50 makaleyi geçiyor, ancak tüm bu bellek profilleme nedeniyle betiğimizi daha yavaş hale getiriyor. Program bittiğinde, bellek profilleyici bize programın bellek tarafından hangi satırların veri eklediğini veya kaldırdığını gösterir. İlk sütun, her satırın yürütüldüğünde ne kadar bellek gerektirdiğini gösterir. İkincisi, her belirli satır için bellekteki artışı gösterir. Burada 50 makaleyi geçtikten sonra, programın zaten 130 megabayt alındığını görebiliriz. Tüm makaleleri işlemeye çalışırken neden bellek tükendiğimizi şimdi anlıyoruz. En fazla belleği gerektiren değişkenlerin makale ve metin olduğunu, sırasıyla yaklaşık dört ve üç megabayt olduğunu görebiliriz. Bunlar işlediğimiz makalelerdir ve makalenin kelimelerini sayarken alanları alması normaldir. Ancak bir makaleyi işledikten sonra o belleği saklamamalıyız. Problemi görebiliyor musunuz? Kodun sonunda, kod makaleyi bir referans tutmak için saklıyor, ancak tüm makaleyi saklıyor. Bir kelimenin tüm makalelerini saklamak istiyorsak başlık veya dizin girişlerini saklayabiliriz, kesinlikle tüm içeriği değil. Bellek yönetimi ve bellek profillemesi hakkında söylenecek çok şey var, ancak burada kapsamaya zamanımız yok. Bir sonraki okumada, sınırlı kaynakları yönetme hakkında bilgi içeren ilginç bağlantıları topladık. Bundan sonra sizi başka bir uygulama sınavı bekliyor.

There's a ton of reasons why an application may request a lot of memory. Sometimes, it's what we need for the program to complete it's task. Sometimes, it's caused by a part of the software misbehaving. First, let's trigger the misbehavior ourselves to see what this looks like. We'll use a terminal called uxterm for that. We've configured this terminal to have a really long scroll buffer. The scroll buffer is that nifty feature that lets us scroll up and see the things that we executed and their output. The contents of the buffer are kept in memory. So if we make it really long and we managed to fill it, will cause our computer to run out of memory. With normal use, it might take ages until it happens, but if we run a command that keeps generating a lot of output, we could manage to fill that buffer pretty quickly. Say we run a command like od-cx/dev/urandom. This command will take the random numbers generated by the urandom device and show them as both characters and hexadecimal numbers. Since the urandom device keeps giving more and more random numbers, it will just keep going. Our command is filling up the scroll buffer, making a computer require more and more memory. In a different terminal, let's open top and check out what's going on. Pressing "Shift M" we tell ton that we want to order the programs by how much memory they are using. We see that the percentage of memory used by uxterm is going up super quickly. Let's stop the process, it's filling up the buffer by pressing "Control C". With that, we stopped the command that was filling the buffer, but the terminal still has that memory allocated, storing all the lines in the scroll buffer. Let's look at the output of top in a bit more detail. There's a bunch of different columns with data about each process. The column labeled RES is the dynamic memory that's preserved for the specific process. The one labeled SHR is for memory that's shared across processes, and the one labeled VIRT lists all the virtual memory allocated for each process. This includes; process specific memory, shared memory, and other shared resources that are stored on disk but maps into the memory of the process. It's usually fine for a process to have a high value in the VIRT column. The one that usually indicates a problem is the RES column. Let's close the other terminal so that it releases all the memory that it reserved. In this example, we saw what a program that keeps requesting more and more memory looks like. This was a super extreme example. Most memory leaks don't happen at the speed. It can usually take a long while until we notice that a program is taking more memory than it should, and it might be hard to tell the difference between memory that's actually needed and memory that's being wasted. But looking at the output of top and comparing it to what it used to be a while back is usually how any investigation into a memory leak starts. Let's look at a different example. We have a script that analyzes the frequency of words in web pages. This script works fine when it's just a few web pages, but if we try to give it all the Wikipedia contents, it starts using up all the memory. Let's run it first and see what happens. This is running and it will take a long while to finish. It's processing a huge amount of articles after all. While this is running, let's look at the output of top in a different terminal and see what we find. We see that there's a bunch of different content stats processes running. That's because our script is using the multiprocessing techniques that we saw in an earlier video to parallelize the processing of the information and get the results as fast as possible. It seems like these scripts are taking a lot of memory. So let's sort it out to see the details. We see that the memory used by one of the processes in particular keeps growing and growing. The application is processing a bunch of data and generating a dictionary with it. So it's expected that it will use some memory but not this much. This looks like the program is storing more than it should in memory. This program is pretty complex. So we could use the help of a memory profiler here to figure out what the problem is. Let's stop it now and use a profiler to figure out where our computer's memory is going. To do that, we'll need to use a simplified version of our code as profiling the memory of a multi-process application is extra hard, and instead of processing all the articles, we'll just handle a few so that we can check up the memory consumption quickly. Let's open our simplified script and have a look. We'll be using a module called memory profiler. This is one of the many different memory profilers available for Python. We've added this app profile label before the main function definition to tell the profiler that we wanted to analyze the memory consumption of it. This type of label is called a decorator and it's used in Python to add extra behavior to functions without having to modify the code. In this case, the extra behavior is measuring the use of memory. The rest of the code is basically the same as the original one, it just uses a single process and is limited to 50 articles instead of the thousands of articles that the other script was going through. We're running the script with the memory profiler enabled. This is just reading through 50 articles but it takes a bunch of time because all that memory profiling makes our script slower. Once the program finishes, the memory profiler gives us information about which lines are adding or removing data from the memory used by the program. The first column shows us the amount of memory required when each line gets executed. The second one shows the increase in memory for each specific line. We see here that after going through 50 articles, the program already took 130 megabytes, no wonder we ran out of memory when we were trying to process all the articles. We can see that the variables that require the most memory are article and text, with about four and of three megabytes respectively. Those are the articles we're processing, and it's fine for them to take space while we're counting the words in the article. But once were done processing one article, we shouldn't keep that memory around. Can you spot the problem? Right at the end, the code is storing the article to keep a reference to it, but it's storing the whole article. If we want to keep a reference to all the articles that include a word, we could store the titles or the index entries, definitely not the whole contents. There's a ton more to say about memory management and memory profiling that we don't have time to cover here. In the next reading, we've gathered a bunch of interesting links to information about managing scarce resources. After that, there's another practice quiz for you.